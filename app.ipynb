{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPESA STATEMENT ANALYZER "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is an AI model that gets an mpesa statement and automatically opens it with  approval from the user  and analyzes the pdf file  to come up with a beviour analysis of our users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kokim/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/kokim/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/kokim/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/kokim/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2 as py \n",
    "import fitz as f \n",
    "import io\n",
    "import tabula\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF successfully decrypted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: Nov 06, 2024 3:24:14 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for base font Times-Roman\n",
      "Nov 06, 2024 3:24:14 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for base font Times-Bold\n",
      "Nov 06, 2024 3:24:14 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for base font Times-Italic\n",
      "Nov 06, 2024 3:24:14 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for base font Times-BoldItalic\n",
      "Nov 06, 2024 3:24:14 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for base font Helvetica\n",
      "Nov 06, 2024 3:24:14 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for base font Helvetica-Bold\n",
      "Nov 06, 2024 3:24:14 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for base font Helvetica-Oblique\n",
      "Nov 06, 2024 3:24:14 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for base font Helvetica-BoldOblique\n",
      "Nov 06, 2024 3:24:14 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for base font Courier\n",
      "Nov 06, 2024 3:24:14 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for base font Courier-Bold\n",
      "Nov 06, 2024 3:24:14 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for base font Courier-Oblique\n",
      "Nov 06, 2024 3:24:14 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for base font Courier-BoldOblique\n",
      "Nov 06, 2024 3:24:14 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for base font Symbol\n",
      "Nov 06, 2024 3:24:14 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
      "Nov 06, 2024 3:24:14 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for Helvetica-Bold\n",
      "Nov 06, 2024 3:24:14 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for Helvetica\n",
      "Nov 06, 2024 3:24:14 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for Helvetica\n",
      "Nov 06, 2024 3:24:16 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for Helvetica-Bold\n",
      "Nov 06, 2024 3:24:16 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for Helvetica\n",
      "Nov 06, 2024 3:24:16 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for Helvetica\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def pdf_decrypt(pdf_password, pdf_file):\n",
    "    \"\"\"A function that decrypts a PDF file and extracts tables using tabula-py.\"\"\"\n",
    "    \n",
    "    # Open the PDF file\n",
    "    with open(pdf_file, \"rb\") as file:\n",
    "        pdf_reader = py.PdfReader(file)\n",
    "\n",
    "        # Check if the PDF is encrypted\n",
    "        if pdf_reader.is_encrypted:\n",
    "            # Attempt to decrypt the PDF with the password\n",
    "            if pdf_reader.decrypt(str(pdf_password)):\n",
    "                print(\"PDF successfully decrypted.\")\n",
    "            else:\n",
    "                raise ValueError(\"Failed to decrypt the PDF. Please check your password.\")\n",
    "        else:\n",
    "            print(\"PDF is not encrypted.\")\n",
    "    \n",
    "    # Extract tables from the PDF using tabula\n",
    "    dfs = tabula.read_pdf(pdf_file,password=str(pdf_password),pages='all')\n",
    "\n",
    "    new_table = dfs[2::2]\n",
    "    #concatenating all the tables in the list into one dataframe\n",
    "    mpesa_df = pd.concat(dfs,axis=0,ignore_index = True)\n",
    "    #Filtering for only the completed transactions\n",
    "    mpesa_df = mpesa_df[mpesa_df['Transaction\\rStatus'] =='Completed']\n",
    "\n",
    "\n",
    "    return mpesa_df # Return the extracted tables as DataFrames\n",
    "\n",
    "\n",
    "# calling the function \n",
    "pdf_password = 37360412\n",
    "pdf_file = \"/home/kokim/projects/Esabu/MPESA_Statement_20190313_to_20190913_254713403607.pdf\"\n",
    "\n",
    "\n",
    "df = pdf_decrypt(pdf_password=pdf_password,pdf_file=pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRANSACTION TYPE       1216\n",
       "PAID IN                1216\n",
       "PAID OUT               1216\n",
       "Receipt No.               0\n",
       "Completion Time           0\n",
       "Details                   0\n",
       "Unnamed: 0             1216\n",
       "Transaction            1216\n",
       "Paid In                 778\n",
       "Withdrawn               438\n",
       "Balance                   0\n",
       "Transaction\\rStatus       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the pdf file \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......\n",
      "The dataframe consists of 1216 rows and 12 columns.\n",
      "Data types:\n",
      "TRANSACTION TYPE        object\n",
      "PAID IN                 object\n",
      "PAID OUT                object\n",
      "Receipt No.             object\n",
      "Completion Time         object\n",
      "Details                 object\n",
      "Unnamed: 0             float64\n",
      "Transaction             object\n",
      "Paid In                 object\n",
      "Withdrawn               object\n",
      "Balance                 object\n",
      "Transaction\\rStatus     object\n",
      "dtype: object\n",
      "\n",
      "Missing values per column:\n",
      "TRANSACTION TYPE       1216\n",
      "PAID IN                1216\n",
      "PAID OUT               1216\n",
      "Receipt No.               0\n",
      "Completion Time           0\n",
      "Details                   0\n",
      "Unnamed: 0             1216\n",
      "Transaction            1216\n",
      "Paid In                 778\n",
      "Withdrawn               438\n",
      "Balance                   0\n",
      "Transaction\\rStatus       0\n",
      "dtype: int64\n",
      "\n",
      "Total duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "def data_program(data):\n",
    "    \"\"\"\n",
    "    A function that assists in data understanding.\n",
    "    It returns the number of rows, columns, data types, missing values, and duplicates.\n",
    "    \"\"\"\n",
    "    # Getting the number of missing values\n",
    "    missing_val = data.isna().sum()\n",
    "\n",
    "    # Getting the number of duplicates\n",
    "    dup_val = data.duplicated().sum()\n",
    "\n",
    "    # Getting the data types\n",
    "    data_types = data.dtypes \n",
    "\n",
    "    # Getting the number of rows and columns\n",
    "    rows, columns = data.shape \n",
    "\n",
    "    # Print a separator for readability\n",
    "    print(\"......\")\n",
    "    \n",
    "    # Returning formatted string with basic info\n",
    "    return (f\"The dataframe consists of {rows} rows and {columns} columns.\\n\"\n",
    "            f\"Data types:\\n{data_types}\\n\\n\"\n",
    "            f\"Missing values per column:\\n{missing_val}\\n\\n\"\n",
    "            f\"Total duplicates: {dup_val}\")\n",
    "\n",
    "# Example call to the function with a dataframe (assuming 'df' is defined)\n",
    "print(data_program(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRANSACTION TYPE</th>\n",
       "      <th>PAID IN</th>\n",
       "      <th>PAID OUT</th>\n",
       "      <th>Receipt No.</th>\n",
       "      <th>Completion Time</th>\n",
       "      <th>Details</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Transaction</th>\n",
       "      <th>Paid In</th>\n",
       "      <th>Withdrawn</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Transaction\\rStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NI94GZ0JPE</td>\n",
       "      <td>2019-09-09 12:24:36</td>\n",
       "      <td>Customer Transfer to 254722794556 - PATRICK\\rG...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2,500.00</td>\n",
       "      <td>521.39</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NI91GYPE0H</td>\n",
       "      <td>2019-09-09 12:13:20</td>\n",
       "      <td>Funds received from 254728109253 - VINCENT\\rKI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3,500.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3,500.00</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NI92GYPG4M</td>\n",
       "      <td>2019-09-09 12:13:20</td>\n",
       "      <td>OD Loan Repayment to 232323 - M-PESA Overdraw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-478.61</td>\n",
       "      <td>3,021.39</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NI80GPKPBS</td>\n",
       "      <td>2019-09-08 22:33:02</td>\n",
       "      <td>OverDraft of Credit Party</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NI80GPKPBS</td>\n",
       "      <td>2019-09-08 22:33:02</td>\n",
       "      <td>Pay Bill Charge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TRANSACTION TYPE PAID IN PAID OUT Receipt No.      Completion Time  \\\n",
       "55              NaN     NaN      NaN  NI94GZ0JPE  2019-09-09 12:24:36   \n",
       "56              NaN     NaN      NaN  NI91GYPE0H  2019-09-09 12:13:20   \n",
       "57              NaN     NaN      NaN  NI92GYPG4M  2019-09-09 12:13:20   \n",
       "58              NaN     NaN      NaN  NI80GPKPBS  2019-09-08 22:33:02   \n",
       "59              NaN     NaN      NaN  NI80GPKPBS  2019-09-08 22:33:02   \n",
       "\n",
       "                                              Details  Unnamed: 0 Transaction  \\\n",
       "55  Customer Transfer to 254722794556 - PATRICK\\rG...         NaN         NaN   \n",
       "56  Funds received from 254728109253 - VINCENT\\rKI...         NaN         NaN   \n",
       "57      OD Loan Repayment to 232323 - M-PESA Overdraw         NaN         NaN   \n",
       "58                          OverDraft of Credit Party         NaN         NaN   \n",
       "59                                    Pay Bill Charge         NaN         NaN   \n",
       "\n",
       "     Paid In  Withdrawn   Balance Transaction\\rStatus  \n",
       "55       NaN  -2,500.00    521.39           Completed  \n",
       "56  3,500.00        NaN  3,500.00           Completed  \n",
       "57       NaN    -478.61  3,021.39           Completed  \n",
       "58     57.00        NaN      2.00           Completed  \n",
       "59       NaN      -2.00      0.00           Completed  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TRANSACTION TYPE', 'PAID IN', 'PAID OUT', 'Receipt No.',\n",
       "       'Completion Time', 'Details', 'Unnamed: 0', 'Transaction', 'Paid In',\n",
       "       'Withdrawn', 'Balance', 'Transaction\\rStatus'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_147508/1411197818.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column].fillna(data[column].mean(), inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Receipt No.</th>\n",
       "      <th>Completion Time</th>\n",
       "      <th>Details</th>\n",
       "      <th>Paid In</th>\n",
       "      <th>Withdrawn</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>NI94GZ0JPE</td>\n",
       "      <td>2019-09-09 12:24:36</td>\n",
       "      <td>Customer Transfer to 254722794556 - PATRICK GI...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.00</td>\n",
       "      <td>521.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>NI91GYPE0H</td>\n",
       "      <td>2019-09-09 12:13:20</td>\n",
       "      <td>Funds received from 254728109253 - VINCENT KIP...</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>NI92GYPG4M</td>\n",
       "      <td>2019-09-09 12:13:20</td>\n",
       "      <td>OD Loan Repayment to 232323 - M-PESA Overdraw</td>\n",
       "      <td>0.0</td>\n",
       "      <td>478.61</td>\n",
       "      <td>3021.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>NI80GPKPBS</td>\n",
       "      <td>2019-09-08 22:33:02</td>\n",
       "      <td>OverDraft of Credit Party</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>NI80GPKPBS</td>\n",
       "      <td>2019-09-08 22:33:02</td>\n",
       "      <td>Pay Bill Charge</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Receipt No.     Completion Time  \\\n",
       "55  NI94GZ0JPE 2019-09-09 12:24:36   \n",
       "56  NI91GYPE0H 2019-09-09 12:13:20   \n",
       "57  NI92GYPG4M 2019-09-09 12:13:20   \n",
       "58  NI80GPKPBS 2019-09-08 22:33:02   \n",
       "59  NI80GPKPBS 2019-09-08 22:33:02   \n",
       "\n",
       "                                              Details  Paid In  Withdrawn  \\\n",
       "55  Customer Transfer to 254722794556 - PATRICK GI...      0.0    2500.00   \n",
       "56  Funds received from 254728109253 - VINCENT KIP...   3500.0       0.00   \n",
       "57      OD Loan Repayment to 232323 - M-PESA Overdraw      0.0     478.61   \n",
       "58                          OverDraft of Credit Party     57.0       0.00   \n",
       "59                                    Pay Bill Charge      0.0       2.00   \n",
       "\n",
       "    Balance  \n",
       "55   521.39  \n",
       "56  3500.00  \n",
       "57  3021.39  \n",
       "58     2.00  \n",
       "59     0.00  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning(data):\n",
    "    \"\"\"\n",
    "    A function to clean Mpesa statements by converting object columns to float, \n",
    "    dropping columns with more than 50% missing values, and dropping duplicates.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove commas from the 'Paid In', 'Withdrawn', and 'Balance' columns before conversion\n",
    "    data[\"Paid In\"] = data['Paid In'].str.replace(',', '').astype(float).fillna(0)\n",
    "    data[\"Withdrawn\"] = data['Withdrawn'].str.replace(',', '').astype(float).fillna(0)\n",
    "    data[\"Balance\"] = data['Balance'].str.replace(',', '').astype(float).fillna(0)\n",
    "    # Remove '\\r' from the 'Name' column\n",
    "    data['Details'] = data['Details'].str.replace('\\r',' ',regex=False)\n",
    "\n",
    "    # converting the completion to datetime data type \n",
    "    data['Completion Time'] = pd.to_datetime(data['Completion Time'])\n",
    "\n",
    "\n",
    "    # replaci\n",
    "\n",
    "    # Dropping columns that have more than 50% missing values\n",
    "    for column in data.columns:\n",
    "        if data[column].isna().sum() / len(data) > 0.5:\n",
    "            data.drop(column, axis=1, inplace=True)\n",
    "        else:\n",
    "            # Filling remaining missing values with the column mean (for numeric columns only)\n",
    "            if pd.api.types.is_numeric_dtype(data[column]):\n",
    "                data[column].fillna(data[column].mean(), inplace=True)\n",
    "\n",
    "    # Dropping duplicates\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Clean column names by removing any line breaks or unusual characters\n",
    "    data.columns = data.columns.str.replace(r'[\\r\\n]', '', regex=True)\n",
    "\n",
    "    # Now, drop the column\n",
    "    data.drop(['TransactionStatus'], axis=1, inplace=True)  \n",
    "\n",
    "\n",
    "    # converting the withdrawn data into  an abs value \n",
    "    data[\"Withdrawn\"] = data[\"Withdrawn\"].abs()\n",
    "\n",
    "\n",
    "\n",
    "    return data\n",
    "\n",
    "# Applying the cleaning function\n",
    "df_cleaned = cleaning(df)\n",
    "df_cleaned.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Feature engineering \n",
    "Getting new columns from existing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Receipt No.</th>\n",
       "      <th>Completion Time</th>\n",
       "      <th>Details</th>\n",
       "      <th>Paid In</th>\n",
       "      <th>Withdrawn</th>\n",
       "      <th>Balance</th>\n",
       "      <th>month_name</th>\n",
       "      <th>day_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>NI94GZ0JPE</td>\n",
       "      <td>2019-09-09 12:24:36</td>\n",
       "      <td>Customer Transfer to 254722794556 - PATRICK GI...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.00</td>\n",
       "      <td>521.39</td>\n",
       "      <td>September</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>NI91GYPE0H</td>\n",
       "      <td>2019-09-09 12:13:20</td>\n",
       "      <td>Funds received from 254728109253 - VINCENT KIP...</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3500.00</td>\n",
       "      <td>September</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>NI92GYPG4M</td>\n",
       "      <td>2019-09-09 12:13:20</td>\n",
       "      <td>OD Loan Repayment to 232323 - M-PESA Overdraw</td>\n",
       "      <td>0.0</td>\n",
       "      <td>478.61</td>\n",
       "      <td>3021.39</td>\n",
       "      <td>September</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>NI80GPKPBS</td>\n",
       "      <td>2019-09-08 22:33:02</td>\n",
       "      <td>OverDraft of Credit Party</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>September</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>NI80GPKPBS</td>\n",
       "      <td>2019-09-08 22:33:02</td>\n",
       "      <td>Pay Bill Charge</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>September</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Receipt No.     Completion Time  \\\n",
       "55  NI94GZ0JPE 2019-09-09 12:24:36   \n",
       "56  NI91GYPE0H 2019-09-09 12:13:20   \n",
       "57  NI92GYPG4M 2019-09-09 12:13:20   \n",
       "58  NI80GPKPBS 2019-09-08 22:33:02   \n",
       "59  NI80GPKPBS 2019-09-08 22:33:02   \n",
       "\n",
       "                                              Details  Paid In  Withdrawn  \\\n",
       "55  Customer Transfer to 254722794556 - PATRICK GI...      0.0    2500.00   \n",
       "56  Funds received from 254728109253 - VINCENT KIP...   3500.0       0.00   \n",
       "57      OD Loan Repayment to 232323 - M-PESA Overdraw      0.0     478.61   \n",
       "58                          OverDraft of Credit Party     57.0       0.00   \n",
       "59                                    Pay Bill Charge      0.0       2.00   \n",
       "\n",
       "    Balance month_name day_name  \n",
       "55   521.39  September   Monday  \n",
       "56  3500.00  September   Monday  \n",
       "57  3021.39  September   Monday  \n",
       "58     2.00  September   Sunday  \n",
       "59     0.00  September   Sunday  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def date_columns(data):\n",
    "    \"\"\"A function that gets the month and day of the week from the columns\"\"\"\n",
    "    # getting the month from the completion time column\n",
    "    data['month_name'] = data['Completion Time'].dt.month_name()\n",
    "    \n",
    "    # Getting the day name\n",
    "    data['day_name'] = data['Completion Time'].dt.day_name()\n",
    "\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "df_cleaned = date_columns(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_categories(data):\n",
    "    \"\"\"Categorize 'Details' column entries and map them to cleaned, user-friendly categories.\"\"\"\n",
    "    \n",
    "    # Define the mapping dictionary\n",
    "    mapped_categories = {\n",
    "        'Customer Transfer to': 'Send Money',\n",
    "        'Pay Bill Fuliza M-Pesa to' : 'Fuliza Loan',\n",
    "        'Customer Transfer Fuliza MPesa': 'Send Money',\n",
    "        'Pay Bill Online': 'Pay Bill',\n",
    "        'Pay Bill to': 'Pay Bill',\n",
    "        'Customer Transfer of Funds\\rCharge': 'Mpesa Charges',\n",
    "        'Pay Bill Charge': 'Mpesa Charges',\n",
    "        'Merchant Payment Online': 'Till No',\n",
    "        'Customer Payment to Small': 'Pochi',\n",
    "        'M-Shwari Withdraw': 'Mshwari Withdraw',\n",
    "        'Business Payment from': 'Bank Transfer',\n",
    "        'Airtime Purchase': 'Airtime Purchase',\n",
    "        'Funds received from': 'Received Money',\n",
    "        'Merchant Payment': 'Till No',\n",
    "        'Customer Withdrawal': 'Cash Withdrawal',\n",
    "        'Withdrawal Charge': 'Mpesa Charges',\n",
    "        'Pay Merchant Charge': 'Mpesa Charges',\n",
    "        'M-Shwari Deposit': 'Mshwari Deposit',\n",
    "        'M-Shwari Loan': 'M-Shwari Loan',\n",
    "        'Deposit of Funds at Agent': 'Customer Deposit',\n",
    "        'OD Loan Repayment to': 'Fuliza Loan Repayment',\n",
    "        'OverDraft of Credit Party': 'Fuliza Loan',\n",
    "        'Customer Transfer Fuliza M-Pesa to':'Send Money',\n",
    "        'Customer Transfer of Funds Charge':'Mpesa Charges',\n",
    "        'KCB M-PESA Withdraw': 'KCB M-PESA Withdraw',\n",
    "        'KCB M-PESA Deposit': 'KCB M-PESA Deposit',\n",
    "        'KCB M-PESA Target Deposit': 'KCB M-PESA Deposit',\t\n",
    "        'Promotion Payment':'Received Money',\n",
    "        'KCB M-PESA Target First Deposit':'KCB M-PESA Deposit',\n",
    "        'Other': 'Other'\n",
    "    }\n",
    "    \n",
    "    # Initialize the 'Category' column with a default value of 'Other'\n",
    "    data['Category'] = 'Other'\n",
    "\n",
    "    # Loop through each phrase in mapped_categories and assign the appropriate category\n",
    "    for phrase, category in mapped_categories.items():\n",
    "        data.loc[data['Details'].str.contains(phrase, case=False, na=False), 'Category'] = phrase\n",
    "\n",
    "    # Map 'Category' to user-friendly names in 'Transaction_Type' column\n",
    "    data['Transaction_Type'] = data['Category'].map(mapped_categories)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def drop_unwanted(data ):\n",
    "    \"\"\"A function that drops unwanted rows  that were created during mapping of the  categories\"\"\"    # Now, drop the column\n",
    "    \n",
    "    data.drop(['Category'], axis=1, inplace=True)  \n",
    "    # Remove rows where 'Transaction_Type' is \"Mpesa Charges\"\n",
    "    data = data.drop(data[data['Transaction_Type'] == \"Mpesa Charges\"].index)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "    \n",
    "# Use the function on your DataFrame\n",
    "df_cleaned = map_categories(df)\n",
    "df_cleaned =drop_unwanted(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Receipt No.</th>\n",
       "      <th>Completion Time</th>\n",
       "      <th>Details</th>\n",
       "      <th>Paid In</th>\n",
       "      <th>Withdrawn</th>\n",
       "      <th>Balance</th>\n",
       "      <th>month_name</th>\n",
       "      <th>day_name</th>\n",
       "      <th>Transaction_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>NI94GZ0JPE</td>\n",
       "      <td>2019-09-09 12:24:36</td>\n",
       "      <td>Customer Transfer to 254722794556 - PATRICK GI...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.00</td>\n",
       "      <td>521.39</td>\n",
       "      <td>September</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Send Money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>NI91GYPE0H</td>\n",
       "      <td>2019-09-09 12:13:20</td>\n",
       "      <td>Funds received from 254728109253 - VINCENT KIP...</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3500.00</td>\n",
       "      <td>September</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Received Money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>NI92GYPG4M</td>\n",
       "      <td>2019-09-09 12:13:20</td>\n",
       "      <td>OD Loan Repayment to 232323 - M-PESA Overdraw</td>\n",
       "      <td>0.0</td>\n",
       "      <td>478.61</td>\n",
       "      <td>3021.39</td>\n",
       "      <td>September</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Fuliza Loan Repayment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>NI80GPKPBS</td>\n",
       "      <td>2019-09-08 22:33:02</td>\n",
       "      <td>OverDraft of Credit Party</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>September</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Fuliza Loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>NI80GPKPBS</td>\n",
       "      <td>2019-09-08 22:33:02</td>\n",
       "      <td>Pay Bill Fuliza M-Pesa to 777711 - TELKOM KENY...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.00</td>\n",
       "      <td>-55.00</td>\n",
       "      <td>September</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Fuliza Loan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Receipt No.     Completion Time  \\\n",
       "55  NI94GZ0JPE 2019-09-09 12:24:36   \n",
       "56  NI91GYPE0H 2019-09-09 12:13:20   \n",
       "57  NI92GYPG4M 2019-09-09 12:13:20   \n",
       "58  NI80GPKPBS 2019-09-08 22:33:02   \n",
       "60  NI80GPKPBS 2019-09-08 22:33:02   \n",
       "\n",
       "                                              Details  Paid In  Withdrawn  \\\n",
       "55  Customer Transfer to 254722794556 - PATRICK GI...      0.0    2500.00   \n",
       "56  Funds received from 254728109253 - VINCENT KIP...   3500.0       0.00   \n",
       "57      OD Loan Repayment to 232323 - M-PESA Overdraw      0.0     478.61   \n",
       "58                          OverDraft of Credit Party     57.0       0.00   \n",
       "60  Pay Bill Fuliza M-Pesa to 777711 - TELKOM KENY...      0.0      55.00   \n",
       "\n",
       "    Balance month_name day_name       Transaction_Type  \n",
       "55   521.39  September   Monday             Send Money  \n",
       "56  3500.00  September   Monday         Received Money  \n",
       "57  3021.39  September   Monday  Fuliza Loan Repayment  \n",
       "58     2.00  September   Sunday            Fuliza Loan  \n",
       "60   -55.00  September   Sunday            Fuliza Loan  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting specific names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/home/kokim/nltk_data'\n    - '/home/kokim/projects/kim_venv/nltk_data'\n    - '/home/kokim/projects/kim_venv/share/nltk_data'\n    - '/home/kokim/projects/kim_venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 39\u001b[0m\n\u001b[1;32m     31\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDetails\u001b[39m\u001b[38;5;124m'\u001b[39m: [\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a sample text that contains the name Alex Smith who is one of the developers of this project.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can also find the surname Jones here.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m     ]\n\u001b[1;32m     36\u001b[0m })\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Apply the extract_named_entities function to each row of the 'Details' column\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtracted_Entities\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDetails\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_named_entities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Explode the 'Extracted_Entities' column into individual rows (one per entity)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m entities_flat \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mexplode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtracted_Entities\u001b[39m\u001b[38;5;124m'\u001b[39m, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/projects/kim_venv/lib/python3.10/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/kim_venv/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/kim_venv/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/projects/kim_venv/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/kim_venv/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[92], line 21\u001b[0m, in \u001b[0;36mextract_named_entities\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_named_entities\u001b[39m(text):\n\u001b[0;32m---> 21\u001b[0m     nltk_results \u001b[38;5;241m=\u001b[39m ne_chunk(pos_tag(\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     22\u001b[0m     entities \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m nltk_result \u001b[38;5;129;01min\u001b[39;00m nltk_results:\n",
      "File \u001b[0;32m~/projects/kim_venv/lib/python3.10/site-packages/nltk/tokenize/__init__.py:142\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    144\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[1;32m    145\u001b[0m     ]\n",
      "File \u001b[0;32m~/projects/kim_venv/lib/python3.10/site-packages/nltk/tokenize/__init__.py:119\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[0;32m~/projects/kim_venv/lib/python3.10/site-packages/nltk/tokenize/__init__.py:105\u001b[0m, in \u001b[0;36m_get_punkt_tokenizer\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_punkt_tokenizer\u001b[39m(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    a lru cache for performance.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    :type language: str\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/kim_venv/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1744\u001b[0m, in \u001b[0;36mPunktTokenizer.__init__\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1743\u001b[0m     PunktSentenceTokenizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/kim_venv/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1749\u001b[0m, in \u001b[0;36mPunktTokenizer.load_lang\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[0;32m-> 1749\u001b[0m     lang_dir \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m load_punkt_params(lang_dir)\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang \u001b[38;5;241m=\u001b[39m lang\n",
      "File \u001b[0;32m~/projects/kim_venv/lib/python3.10/site-packages/nltk/data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/home/kokim/nltk_data'\n    - '/home/kokim/projects/kim_venv/nltk_data'\n    - '/home/kokim/projects/kim_venv/share/nltk_data'\n    - '/home/kokim/projects/kim_venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kokim/nltk_data/tokenizers/punkt\n",
      "/home/kokim/nltk_data/taggers/averaged_perceptron_tagger\n",
      "/home/kokim/nltk_data/chunkers/maxent_ne_chunker\n",
      "/home/kokim/nltk_data/corpora/words\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.data.find('tokenizers/punkt'))\n",
    "print(nltk.data.find('taggers/averaged_perceptron_tagger'))\n",
    "print(nltk.data.find('chunkers/maxent_ne_chunker'))\n",
    "print(nltk.data.find('corpora/words'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kim_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
